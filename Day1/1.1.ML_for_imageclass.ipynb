{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Brief Introduction to Machine Learning for image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Written by Dr Daniel Buscombe, Northern Arizona University\n",
    "\n",
    "> Part of a series of notebooks for image recognition and classification using deep convolutional neural networks\n",
    "\n",
    "\n",
    "![](figs/Picture4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What constitutes an 'image'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're considering a broad/loose definition of the word image. \n",
    "\n",
    "Not just a photograph \n",
    "\n",
    "Almost any dataset >= 2D that is naturally a raster or is \"rasterizable\" \n",
    "\n",
    "(e.g. ultrasonic, radar, sonar, seismic, DEM, etc, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "* a means of building models of data\n",
    "\n",
    "* involves building mathematical models to help understand data. \n",
    "\n",
    "* \"Learning\" is the process of giving these models tunable parameters that can be adapted to observed data; in this way the program can be considered to be \"learning\" from the data. \n",
    "\n",
    "Learning how the data is structured so that it can predict\n",
    "\n",
    "* Once these models have been fit to previously seen data, they can be used to predict and understand aspects of newly observed data. \n",
    "\n",
    "* The fundamental goal is to *generalize* (a program that memorizes its observations may not perform its task well)\n",
    "\n",
    "Not to perfectly fit it is overfitted if it doesn't generalize well.\n",
    "\n",
    "classification is discrete groups, regressioni s continuous fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories\n",
    "\n",
    "![](https://www.mathworks.com/content/mathworks/www/en/discovery/machine-learning/jcr:content/mainParsys3/discoverysubsection_1965078453/mainParsys3/image_2128876021_cop.adapt.full.high.svg/1523365053391.svg)\n",
    "\n",
    "### 1. Supervised learning \n",
    "* Involves modeling the relationship between measured features of data and some label associated with the data\n",
    "* Once this model is determined, it can be used to apply labels to new, unknown data. \n",
    "* This is further subdivided into classification tasks and regression tasks\n",
    "    * Classification: the labels are discrete categories\n",
    "    * Regression: the labels are continuous quantities\n",
    "\n",
    "![](https://lakshaysuri.files.wordpress.com/2017/03/sup-vs-unsup.png?w=648)\n",
    "\n",
    "### 2. Unsupervised learning\n",
    "* Involves modeling the features of a dataset without reference to any label\n",
    "* These models include tasks such as clustering and dimensionality reduction\n",
    "    * Clustering algorithms: identify distinct groups of data\n",
    "    * Dimensionality reduction algorithms: search for more succinct representations of the data\n",
    "    \n",
    "***    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 'typical' supervised learning workflow\n",
    "\n",
    "![](https://morganpolotan.files.wordpress.com/2015/04/supervised_learning_model2.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdn.intellipaat.com/wp-content/uploads/2015/11/machine-learning-algorithms-460x255.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning for image analysis\n",
    "\n",
    "classification and localization is where it is too\n",
    "\n",
    "#### 1. Image recognition\n",
    "\n",
    "For example, recognizing faces ...\n",
    "\n",
    "![](figs/Picture1.png)\n",
    "\n",
    "... classifying organisms ... etc\n",
    "\n",
    "![](figs/Picture2.png)\n",
    "\n",
    "***\n",
    "\n",
    "#### 2. Semantic segmentation\n",
    "\n",
    "Classifying each pixel in each image\n",
    "\n",
    "![](figs/Picture3.png)\n",
    "\n",
    "\n",
    "#### 3. Others\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*6ugm_qZgwuWMnIrWJUR3rg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distinction between Machine and Deep Learning\n",
    "\n",
    "Machine learning ...\n",
    "* requires extracting features from data to input to the model\n",
    "* requires fine-tuning of model architecture\n",
    "* requires fine-tuning of model hyperparameters\n",
    "* performance tends to plateau with more data\n",
    "* lots of different models\n",
    "\n",
    "Deep learning ...\n",
    "* automatically extract features from data\n",
    "* automatically fine-tunes hyperparameters\n",
    "* performance doesn't tend to plateau with more data\n",
    "* requires fine-tuning of model architecture\n",
    "* just one model - the artificial neural network\n",
    "\n",
    "![](https://images.xenonstack.com/blog/machine-learning-vs-deep-learning.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Hyperparameters and model validation\n",
    "\n",
    "The basic recipe for applying a supervised machine learning model:\n",
    "\n",
    "* Choose a class of model\n",
    "* Choose model hyperparameters\n",
    "* Fit the model to the training data\n",
    "* Use the model to predict labels for new data\n",
    "\n",
    "![](https://media.mljar.com/blog/are-hyper-parameters-really-important-in-machine-learning/head/are-hyper-parameters-really-important-in-machine-learning.jpg)\n",
    "\n",
    "\n",
    "### What is a Model Parameter?\n",
    "A model parameter is a configuration variable that is internal to the model and whose value can be estimated from data.\n",
    "\n",
    "* They are required by the model when making predictions.\n",
    "* They values define the skill of the model on your problem.\n",
    "* They are estimated or learned from data.\n",
    "* They are often not set manually by the practitioner.\n",
    "* They are often saved as part of the learned model.\n",
    "\n",
    "\n",
    "### What is a Model Hyperparameter?\n",
    "A model hyperparameter is a configuration that is external to the model and whose value cannot be estimated from data.\n",
    "\n",
    "* They are often used in processes to help estimate model parameters.\n",
    "* They are often specified by the practitioner.\n",
    "* They are often tuned for a given predictive modeling problem.\n",
    "\n",
    "\n",
    "![](https://image.slidesharecdn.com/icmltalk-160620125922/95/hyperparameter-optimization-with-approximate-gradient-2-638.jpg?cb=1467797347)\n",
    "\n",
    "After choosing a model and its hyperparameters, we can estimate how effective it is by applying it to some of the training data and comparing the prediction to the known value.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our estimator is underperforming, how should we move forward?\n",
    "\n",
    "* Use a more complicated/more flexible model\n",
    "* Use a less complicated/less flexible model\n",
    "* Gather more training samples\n",
    "* Gather more data to add features to each sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, the question of \"the best model\" is about finding a sweet spot in the tradeoff between bias and variance. \n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*x8CBE7eAbaifwM15KNHuUA.png)\n",
    "\n",
    "### Bias\n",
    "If a model doesn't have enough flexibility to suitably account for all the features in the data, it is said to underfit the data. Another way of saying this is that the model has high bias.\n",
    "\n",
    "### Variance\n",
    "If a model fit has enough flexibility to nearly perfectly account for the fine features in the data, but its precise form seems to be more reflective of the particular noise properties of the data rather than the intrinsic properties of whatever process generated that data. \n",
    "\n",
    "Such a model is said to overfit the data: that is, it has so much model flexibility that the model ends up accounting for random errors as well as the underlying data distribution; another way of saying this is that the model has high variance.\n",
    "\n",
    "\n",
    "If we imagine that we have some ability to tune the model complexity, we would expect the training and validation error to behave as illustrated in the following figure\n",
    "\n",
    "![](https://www.learnopencv.com/wp-content/uploads/2017/02/Bias-Variance-Tradeoff-In-Machine-Learning-1.png)\n",
    "\n",
    "\n",
    "* The training error is lower than the validation error\n",
    "    * This means that the model will be a better fit to data it has seen than to data it has not seen.\n",
    "\n",
    "* For very low model complexity (a high-bias model), the training data is under-fit\n",
    "    * the model is a poor predictor both for the training data and for any previously unseen data.\n",
    "\n",
    "* For very high model complexity (a high-variance model), the training data is over-fit\n",
    "    * the model predicts the training data very well, but fails for any previously unseen data.\n",
    "\n",
    "* For some intermediate value, the validation curve has a maximum. This level of complexity indicates a suitable trade-off between bias and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning curves\n",
    "\n",
    "A plot of the training/validation error with respect to the size of the training set is known as a learning curve.\n",
    "\n",
    "The general behavior we would expect from a learning curve is:\n",
    "\n",
    "* A model of a given complexity will overfit a small dataset\n",
    "    * the training score will be relatively high, while the validation score will be relatively low.\n",
    "* A model of a given complexity will underfit a large dataset\n",
    "    * the training score will decrease, but the validation score will increase.\n",
    "* A model will never, except by chance, give a better score to the validation set than the training set\n",
    "    * this means the curves should keep getting closer together but never cross.\n",
    "\n",
    "\n",
    "![](http://www.yuthon.com/images/typical-learning-curve-for-high-variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have enough points that a particular model has converged, adding more training data will not help you! The only way to increase model performance in this case is to use another (often more complex) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing Hyperparameters: Grid Search\n",
    "\n",
    "Models generally have more than one knob to turn, and thus plots of validation and learning curves change from lines to multi-dimensional surfaces. In these cases, such visualizations are difficult and we would rather simply find the particular model that maximizes the validation score.\n",
    "\n",
    "Grid searching allows us to do this\n",
    "\n",
    "![](https://i.stack.imgur.com/02p4O.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "## Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hoonhout et al 2015](https://www.sciencedirect.com/science/article/pii/S0378383915001313) \"An automated method for semantic classification of regions in coastal images\" Coastal Engineering 105, 1-12\n",
    "\n",
    "Objective: develop a ML classifier for semantic segmentation of images of coasts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four steps: \n",
    "1. a manually annotated dataset of coastal images is oversegmented into superpixels; \n",
    "2. for all images in the dataset an extensive set of features is extracted; \n",
    "3. a suitable classification model is trained using the manually annotated data; and \n",
    "4. the trained model is used to automatically classify future images. \n",
    "\n",
    "***\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversegmentation\n",
    "\n",
    "Oversegmentation is the process of subdividing the image in smaller segments of similar pixels, which are called superpixels\n",
    "\n",
    "Used to reduce the number of features (data dimensionality reduction)\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "The classification algorithm uses 1727 features from the categories 1. position, 2. intensity, 3. shape, and 4. texture.\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine (SVM) classifier\n",
    "\n",
    "Given labeled training data (supervised learning), the algorithm outputs an optimal hyperplane which categorizes new examples. \n",
    "\n",
    "More info [here](https://machinelearningmastery.com/support-vector-machines-for-machine-learning/)\n",
    "\n",
    "![](https://docs.opencv.org/2.4/_images/optimal-hyperplane.png)\n",
    "\n",
    "![](http://www.statsoft.com/textbook/graphics/SVMIntro3.gif)\n",
    "\n",
    "***\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Aggregated confusion matrix\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr8.jpg)\n",
    "\n",
    "Best and worst performance\n",
    "\n",
    "![](https://ars.els-cdn.com/content/image/1-s2.0-S0378383915001313-gr9.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
